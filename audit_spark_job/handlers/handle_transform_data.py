"""
    This module handles the transformations for this training spark job.
"""

# Standard Library Imports <- This is not required but useful to separate out imports
from helper_audit import audit
from helper_printer import print_header
from pyspark.sql import DataFrame, Window
from pyspark.sql import functions as F
import helper_spark_data_generator as sdg


def job_transform_phase(dataframe: DataFrame):
    """
    1. Mocks the input dataframe with a record change type. This is a typical step in ETL jobs. By determining the
    record change type, you can handle the data differently as the job requires.
    2. Calculates the grand total for the `amount` column. This allows us to calculate the percent of total for each
    record.
    3. Creates a new column for each field that is of string datatype and changes the value to uppercase when the
    record change type value is update.
    4. Creates a new column that calculates the percent of total for each record.

    Examples:
        process_df = handle_transaction_data.job_transform_phase(dataframe=input_df)

    Args:
        dataframe (DataFrame): The dataframe to execute the transformations

    Returns:
        DataFrame
    """
    print_header("TRANSFORM 1 of 3\n"
                 "\n"
                 "Determine Record Change Type\n"
                 " ╠ Added a new column named `random_change_type` that is randomly\n"
                 " ╚ generated by a UDF and is one of: new, update, delete, no_change.\n")
    change_type_df = dataframe \
        .select(F.col("*"),
                sdg.get_record_action().alias("random_change_type")) \
        .cache()
    # .cache() is required for 2 reasons
    #   1. As random_change_type is a UDF. When show is called, it generates the DF and gets new values for random
    #      change type
    #   2. Speeds up the process as the DF doesn't need to regenerate
    change_type_df.show(truncate=False)
    # AUDIT
    audit_change_type_df = change_type_df \
        .select(F.col("random_change_type"),
                F.when(F.lower(F.col("random_change_type")) == F.lit("delete"), F.lit(1))
                .otherwise(F.lit(0)).alias("delete"),
                F.when(F.lower(F.col("random_change_type")) == F.lit("update"), F.lit(1))
                .otherwise(F.lit(0)).alias("update"),
                F.when(F.lower(F.col("random_change_type")) == F.lit("insert"), F.lit(1))
                .otherwise(F.lit(0)).alias("insert"),
                F.when(F.lower(F.col("random_change_type")) == F.lit("no_change"), F.lit(1))
                .otherwise(F.lit(0)).alias("no_change")) \
        .agg(F.sum(F.col("delete")).alias("delete_count"),
             F.sum(F.col("update")).alias("update_count"),
             F.sum(F.col("insert")).alias("insert_count"),
             F.sum(F.col("no_change")).alias("no_change_count"))
    audit.input.populate_from_df(df=audit_change_type_df)
    audit.print()

    print_header("TRANSFORM 2 of 3\n"
                 "\n"
                 "Calculate Grant Total For Amount\n"
                 " ╠ Added a new column that uses a window function to add the\n"
                 " ╚ Grand Total for Amount for new, update and delete.")
    grand_total_df = change_type_df \
        .where(F.col("random_change_type") != "no_change") \
        .withColumn("amount_grand_total", (F.sum(F.col("amount")).over(Window.orderBy(F.lit(1)))))
    grand_total_df.show(truncate=False)

    print_header("TRANSFORM 3 of 3\n"
                 "\n"
                 "Process Data Based On Change Type & Calculate Percent Of Total\n"
                 " ╠ Updated (actually a new column of the same name) all column datatypes of string\n"
                 " ╠ to uppercase when the change type is `update`.\n"
                 " ╚ Added a new column that calculates the percent of total for amount")
    column_select_list = []
    for col_name, col_type in grand_total_df.dtypes:
        if col_type == "string":
            column_select_list.append(
                F.when(F.col("random_change_type") == "update", F.upper(F.col(col_name)))
                .otherwise(F.col(col_name))
                .alias(col_name))
        else:
            column_select_list.append(F.col(col_name).alias(col_name))
    process_df = grand_total_df \
        .select(*column_select_list,
                F.round(F.col("amount") / F.col("amount_grand_total"), 2).alias("amount_percent_of_total")) \
        .drop(F.col("amount_grand_total"))
    process_df.show(truncate=False)

    return process_df
