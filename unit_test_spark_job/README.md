```shell
project root
├── base_spark_job
├── audit_spark_job
├── logging_spark_job
├── unit_test_spark_job ◄
├── self_heal_spark_job
└── single_execution_spark_job
```

# Single Execution Spark Job

[[_TOC_]]

## Purpose

---

## Job

### Requirements

1. Check for dirty data in transform
    1. Test for edge cases (null, upper case, not in (delete, update, insert, no_change))
    2. Test result of strings are uppercase for strings

### Steps

### Data Flow Diagram

```shell
```

### Related Docs

[Console Job Output](CONSOLE.md)

---

## How You Can Help

While every effort has been made to make this project meet all development guidelines and be 100% accurate, I won't
pretend it is perfect. Any questions, comments, or concerns are expected to be raised to the team and/or your manager.

---

## Contact

If you have any questions, comments, concerns or suggestions, please contact the team or your manager. Any PySpark
developer should have the knowledge to help understand the content contained here in. This was originally written
by 📷-Cameron Larson and reviewed by 🍞-Brad Transtrum and 🧢-Bill Larkin.

---
